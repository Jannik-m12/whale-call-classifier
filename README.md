# ğŸ‹ Whale Call Classifier

## Overview
The Whale Call Classifier is a deep learning project that classifies marine mammal calls from audio recordings. It uses the [Watkins Marine Mammal Sound Database](https://huggingface.co/datasets/confit/wmms-parquet) and converts raw audio into mel-spectrograms, which are then used to train a convolutional neural network (CNN) to identify up to 27 whale and marine mammal species.

---

## Project Structure
```
whale-call-classifier/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ watkins_dataset/        # Raw HuggingFace dataset (downloaded locally)
â”‚   â””â”€â”€ processed/              # Preprocessed spectrograms and labels
â”‚       â”œâ”€â”€ X_train_variable.pkl
â”‚       â”œâ”€â”€ X_test_variable.pkl
â”‚       â”œâ”€â”€ y_train.npy
â”‚       â”œâ”€â”€ y_test.npy
â”‚       â””â”€â”€ species_mapping.pkl
â”œâ”€â”€ models/                     # Saved Keras model checkpoints
â”‚   â”œâ”€â”€ best_model.keras
â”‚   â”œâ”€â”€ best_baseline_model.keras
â”‚   â”œâ”€â”€ best_custom_model.keras
â”‚   â”œâ”€â”€ best_enhanced_model.keras
â”‚   â””â”€â”€ best_improved_model.keras
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for exploration & training
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing_validation.ipynb
â”‚   â”œâ”€â”€ 03_cnn_training.ipynb
â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ download.py         # Downloads dataset from HuggingFace
â”‚   â”‚   â””â”€â”€ preprocess.py       # Audio â†’ mel-spectrogram pipeline
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ extract_features.py # MFCC, chroma, spectrogram feature extraction
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py            # Model training & saving
â”‚   â”‚   â”œâ”€â”€ evaluate.py         # Accuracy, precision, recall, F1 evaluation
â”‚   â”‚   â””â”€â”€ predict.py          # Load model and run inference
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â””â”€â”€ plot_spectrograms.py # Spectrogram plotting utilities
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ audio_utils.py      # Audio loading, saving, MFCC, mel-spectrogram
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocess.py      # Unit tests for preprocessing pipeline
â”‚   â””â”€â”€ test_model.py           # Unit tests for model training & evaluation
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # Project configuration
â”œâ”€â”€ results/                    # Evaluation results and plots
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

---

## Pipeline

```
Raw Audio (.flac/.wav)
        â”‚
        â–¼
  Audio Decoding          (soundfile)
        â”‚
        â–¼
  Mono Conversion &       (librosa)
  Resampling â†’ 16 kHz
        â”‚
        â–¼
  Mel-Spectrogram         (128 mel bands, variable length)
        â”‚
        â–¼
  Filter by Duration      (2s â€“ 60s)
        â”‚
        â–¼
  CNN Classification      (TensorFlow/Keras)
        â”‚
        â–¼
  Species Prediction      (27 classes)
```

---

## Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd whale-call-classifier
   ```

2. **Create and activate a virtual environment (recommended):**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

---

## Usage

### 1. Download the Dataset
```bash
python src/data/download.py
```
This downloads the Watkins Marine Mammal Sound Database from HuggingFace and saves it to `./data/watkins_dataset/`.

### 2. Preprocess the Data
```bash
python src/data/preprocess.py
```
Converts raw audio to variable-length mel-spectrograms and saves them to `./data/processed/`. Only species with **â‰¥ 21 recordings** are included (27 species total).

### 3. Train the Model
Use the Jupyter notebooks in `notebooks/` for interactive training:
```bash
jupyter notebook notebooks/03_cnn_training.ipynb
```
Or use the training module directly:
```python
from src.models.train import train_model, save_model
history = train_model(X_train, y_train, model, epochs=30)
save_model(model, "./models/best_model.keras")
```

### 4. Evaluate the Model
```python
from src.models.evaluate import evaluate_model
metrics = evaluate_model(model, X_test, y_test)
print(metrics)  # accuracy, precision, recall, f1_score
```

### 5. Run Inference
```bash
python src/models/predict.py <model_path> <features>
```

---

## Configuration

Key parameters in [`src/data/preprocess.py`](src/data/preprocess.py):

| Parameter | Value | Description |
|---|---|---|
| `SAMPLE_RATE` | 16000 Hz | Target sample rate |
| `N_MELS` | 128 | Number of mel frequency bands |
| `HOP_LENGTH` | 512 | STFT hop length |
| `MIN_SAMPLES` | 21 | Minimum recordings per species |
| `min_duration` | 2.0 s | Minimum clip duration |
| `max_duration` | 60.0 s | Maximum clip duration |

---

## Running Tests

```bash
pytest tests/
```

Tests cover:
- **Mel-spectrogram output shape and validity** (`tests/test_preprocess.py`)
- **Processed data integrity** (shape, species mapping with 27 classes)
- **Model training and evaluation** (`tests/test_model.py`)

---

## Species

The classifier covers **27 marine mammal species** from the Watkins dataset (all species with â‰¥ 21 recordings). The full mapping is saved in `./data/processed/species_mapping.pkl`.

---

## Dependencies

Key libraries (see [`requirements.txt`](requirements.txt) for full list):

- `tensorflow` â€” CNN model training & inference
- `librosa` â€” Audio processing & mel-spectrogram generation
- `soundfile` â€” Audio decoding
- `datasets` (HuggingFace) â€” Dataset loading
- `numpy`, `scikit-learn` â€” Data handling & metrics
- `matplotlib` â€” Visualization
- `pytest` â€” Testing

---

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

---

## License

This project is licensed under the **MIT License**. See the `LICENSE` file for details.